
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>日活需求(kafka精准一次性消费) 分别用sparkstreaming和flink实现 | The last tear in the Atlantic</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="article">
<meta property="og:title" content="日活需求(kafka精准一次性消费) 分别用sparkstreaming和flink实现">
<meta property="og:url" content="https://ycfn97.xyz/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/index.html">
<meta property="og:site_name" content="The last tear in the Atlantic">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ycfn97.xyz/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/1.jpg">
<meta property="og:image" content="https://ycfn97.xyz/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/kibana%E5%8F%AF%E8%A7%86%E5%8C%96.jpg">
<meta property="og:image" content="https://ycfn97.xyz/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/%E6%97%A5%E6%B4%BB.jpg">
<meta property="og:image" content="https://ycfn97.xyz/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/spark.jpg">
<meta property="og:image" content="https://ycfn97.xyz/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/%E4%B8%80%E8%87%B4%E6%80%A71.jpg">
<meta property="og:image" content="https://ycfn97.xyz/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/%E4%B8%80%E8%87%B4%E6%80%A72.jpg">
<meta property="og:image" content="https://ycfn97.xyz/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/redis1.jpg">
<meta property="og:image" content="https://ycfn97.xyz/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/redis2.jpg">
<meta property="og:image" content="https://ycfn97.xyz/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/%E6%A3%80%E6%9F%A5%E7%82%B9.jpg">
<meta property="article:published_time" content="2020-12-08T11:11:38.792Z">
<meta property="article:modified_time" content="2020-12-08T12:04:56.019Z">
<meta property="article:author" content="ycfn97">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ycfn97.xyz/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/1.jpg">
  
    <link rel="alternative" href="/atom.xml" title="The last tear in the Atlantic" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
<link rel="stylesheet" href="/css/style.css">

  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  

  
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?029e85d94060b2a4054a349dc92bef7f";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
 


<meta name="generator" content="Hexo 5.2.0"></head>
<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">The last tear in the Atlantic</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" class="search-form">
          <input type="search" name="word" maxlength="20" class="search-form-input" placeholder="Search">
          <input type="submit" value="" class="search-form-submit">
          <input name=tn type=hidden value="bds">
          <input name=cl type=hidden value="3">
          <input name=ct type=hidden value="2097152">
          <input type="hidden" name="si" value="ycfn97.xyz">
        </form>
      </div>
    </div>
  </div>
</header>
    <div class="outer">
      <section id="main"><article id="post-日活需求(kafka精准一次性消费)-分别用sparkstreaming和flink实现" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/" class="article-date">
  <time datetime="2020-12-08T11:11:38.792Z" itemprop="datePublished">2020-12-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      日活需求(kafka精准一次性消费) 分别用sparkstreaming和flink实现
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/1.jpg"></p>
<a id="more"></a>

<p>指标需求：求出当日新增日活，并通过kibana按照需求做实时展示</p>
<p><img src="/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/kibana%E5%8F%AF%E8%A7%86%E5%8C%96.jpg"></p>
<p>实现思路1：sparkstreaming消费kafka数据，使用redis保存kafka偏移量，确保程序意外退出后能从之前的偏移量继续消费，并保存至es做去重。</p>
<p>实现思路2：flink消费kafka数据，使用状态后端(state backend)保存data source中来自kafka的偏移量，确保程序宕机后重启能从之前的偏移位置重新消费。</p>
<blockquote>
<p><em>端到端exactly-once实现：</em></p>
<p>​    <u><em>source端：kafka偏移量</em></u></p>
<p>​    <u><em>内部：sparkingstreaming：redis做去重同时保存偏移量</em></u></p>
<p>​                <u><em>flink：state backend状态后端</em></u></p>
<p>​    <u><em>sink端：es的id不可重复，做幂等性写入</em></u></p>
</blockquote>
<p>项目局部架构：</p>
<p><img src="/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/%E6%97%A5%E6%B4%BB.jpg"></p>
<p>sparkingstreaming流程图：</p>
<p><img src="/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/spark.jpg"></p>
<p>flink端到端状态一致性过程：</p>
<p><img src="/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/%E4%B8%80%E8%87%B4%E6%80%A71.jpg"></p>
<p><img src="/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/%E4%B8%80%E8%87%B4%E6%80%A72.jpg"></p>
<h2 id="demo："><a href="#demo：" class="headerlink" title="demo："></a>demo：</h2><h4 id="sparkstreaming使用scala实现："><a href="#sparkstreaming使用scala实现：" class="headerlink" title="sparkstreaming使用scala实现："></a>sparkstreaming使用scala实现：</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DauApp</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建配置文件对象 注意：Streaming程序至少不能设置为local，至少需要2个线程</span></span><br><span class="line">    <span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;Spark01_W&quot;</span>).setMaster(<span class="string">&quot;local[4]&quot;</span>)</span><br><span class="line">      </span><br><span class="line">    <span class="comment">//创建Spark Streaming上下文环境对象O</span></span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf,<span class="type">Seconds</span>(<span class="number">3</span>))</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">val</span> gmallstartup = <span class="string">&quot;GMALL_STARTUP_0105&quot;</span></span><br><span class="line">    <span class="keyword">val</span> daugroup = <span class="string">&quot;DAU_GROUP&quot;</span></span><br><span class="line">      </span><br><span class="line">     <span class="comment">//使用偏移量工具类从redis获取上一次的kafka偏移量</span></span><br><span class="line">    <span class="keyword">val</span> partitionToLong = util.<span class="type">OffsetManager</span>.getOffset(gmallstartup, daugroup)</span><br><span class="line">      </span><br><span class="line">      <span class="comment">//判断是否第一次消费，如果不是则从偏移量开始消费数据流</span></span><br><span class="line">    <span class="keyword">var</span> inputStream: <span class="type">InputDStream</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]]=<span class="literal">null</span></span><br><span class="line">    <span class="keyword">if</span> (partitionToLong!=<span class="literal">null</span>&amp;&amp;partitionToLong.size&gt;<span class="number">0</span>)&#123;</span><br><span class="line">      inputStream = util.<span class="type">MyKafkaUtil</span>.getKafkaStream(gmallstartup, ssc, partitionToLong, daugroup)</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">      inputStream=util.<span class="type">MyKafkaUtil</span>.getKafkaStream(gmallstartup,ssc)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//得到本批次的偏移量的结束位置，用于更新redis中的偏移量</span></span><br><span class="line">    <span class="keyword">var</span>  offsetRanges: <span class="type">Array</span>[<span class="type">OffsetRange</span>] = <span class="type">Array</span>.empty[<span class="type">OffsetRange</span>]</span><br><span class="line">    <span class="keyword">val</span>  inputGetOffsetDstream: <span class="type">DStream</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = inputStream.transform &#123; rdd =&gt;</span><br><span class="line">      offsetRanges = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges  <span class="comment">//driver? executor?  //周期性的执行</span></span><br><span class="line">      rdd</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//补充日志json时间字段</span></span><br><span class="line">    <span class="keyword">val</span> value1 = inputGetOffsetDstream.map(record =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> str = record.value()</span><br><span class="line">      <span class="keyword">val</span> nObject = <span class="type">JSON</span>.parseObject(str)</span><br><span class="line">      <span class="keyword">val</span> long = nObject.getLong(<span class="string">&quot;ts&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> str1 = <span class="keyword">new</span> <span class="type">SimpleDateFormat</span>(<span class="string">&quot;yyyy-MM-dd HH&quot;</span>).format(<span class="keyword">new</span> <span class="type">Date</span>(long))</span><br><span class="line">      <span class="keyword">val</span> strings = str1.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">      nObject.put(<span class="string">&quot;dt&quot;</span>, strings(<span class="number">0</span>))</span><br><span class="line">      nObject.put(<span class="string">&quot;hr&quot;</span>, strings(<span class="number">1</span>))</span><br><span class="line">      nObject</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//写入redis以及设置保存时间为24小时，并通过是否写入redis成功判断过滤条数</span></span><br><span class="line">    <span class="keyword">val</span> value2 = value1.mapPartitions(iter =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> client = util.<span class="type">RedisUtil</span>.getJedisClient</span><br><span class="line">      <span class="keyword">val</span> buffer = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">JSONObject</span>]()</span><br><span class="line">      <span class="keyword">val</span> list = iter.toList</span><br><span class="line">      println(<span class="string">&quot;过滤前:&quot;</span> + list.size)</span><br><span class="line">      <span class="keyword">for</span> (jsonObj &lt;- list) &#123;</span><br><span class="line">        <span class="keyword">val</span> str = jsonObj.getString(<span class="string">&quot;dt&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> str1 = jsonObj.getJSONObject(<span class="string">&quot;common&quot;</span>).getString(<span class="string">&quot;mid&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> str2 = <span class="string">&quot;dau:&quot;</span> + str</span><br><span class="line">        <span class="keyword">val</span> long = client.sadd(str2, str1)</span><br><span class="line">        client.expire(str2, <span class="number">3600</span> * <span class="number">24</span>)</span><br><span class="line">        <span class="keyword">if</span> (long == <span class="number">1</span>) &#123;</span><br><span class="line">          buffer += jsonObj</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      client.close()</span><br><span class="line">      println(<span class="string">&quot;过滤后:&quot;</span> + buffer.size)</span><br><span class="line">      list.toIterator</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line">      <span class="comment">//写入es</span></span><br><span class="line">    value2.foreachRDD &#123; rdd =&gt; &#123;</span><br><span class="line">      rdd.foreachPartition(rdd =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> list = rdd.toList</span><br><span class="line">        <span class="keyword">val</span> tuples = list.map(jsonObj =&gt; &#123;</span><br><span class="line">          <span class="keyword">val</span> nObject = jsonObj.getJSONObject(<span class="string">&quot;common&quot;</span>)</span><br><span class="line">          <span class="keyword">val</span> info = bean.<span class="type">DauInfo</span>(nObject.getString(<span class="string">&quot;mid&quot;</span>),</span><br><span class="line">            nObject.getString(<span class="string">&quot;uid&quot;</span>),</span><br><span class="line">            nObject.getString(<span class="string">&quot;ar&quot;</span>),</span><br><span class="line">            nObject.getString(<span class="string">&quot;ch&quot;</span>),</span><br><span class="line">            nObject.getString(<span class="string">&quot;vc&quot;</span>),</span><br><span class="line">            jsonObj.getString(<span class="string">&quot;dt&quot;</span>),</span><br><span class="line">            jsonObj.getString(<span class="string">&quot;hr&quot;</span>),</span><br><span class="line">            <span class="string">&quot;00&quot;</span>,</span><br><span class="line">            jsonObj.getLong(<span class="string">&quot;ts&quot;</span>))</span><br><span class="line">          (info.mid, info)</span><br><span class="line">        &#125;)</span><br><span class="line">        <span class="keyword">val</span> str = <span class="keyword">new</span> <span class="type">SimpleDateFormat</span>(<span class="string">&quot;yyyy-MM-dd&quot;</span>).format(<span class="keyword">new</span> <span class="type">Date</span>())</span><br><span class="line">        util.<span class="type">MyEsUtil</span>.bulkDoc(tuples, <span class="string">&quot;gmall_dau_info_&quot;</span> + str)</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">      util.<span class="type">OffsetManager</span>.saveOffset(gmallstartup, daugroup, offsetRanges)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//    value.map(_.value()).print()</span></span><br><span class="line">    <span class="comment">//启动采集器</span></span><br><span class="line">    ssc.start()</span><br><span class="line">    <span class="comment">//默认情况下，上下文对象不能关闭</span></span><br><span class="line">    <span class="comment">//ssc.stop()</span></span><br><span class="line">    <span class="comment">//等待采集结束，终止上下文环境对象</span></span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>使用到的utils工具类可以去<a target="_blank" rel="noopener" href="https://github.com/ycfn97/gmall-utils.git">GitHub</a>拉取</p>
<h4 id="flink使用java实现："><a href="#flink使用java实现：" class="headerlink" title="flink使用java实现："></a>flink使用java实现：</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> app;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSON;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.MapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.RuntimeContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.TimeCharacteristic;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.elasticsearch.util.RetryRejectedExecutionFailureHandler;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.util.serialization.SimpleStringSchema;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.HttpHost;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.index.IndexRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.Requests;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Copyright(c) 2020-2021 sparrow All Rights Reserved</span></span><br><span class="line"><span class="comment"> * Project: gmall2020-parent</span></span><br><span class="line"><span class="comment"> * Package: app</span></span><br><span class="line"><span class="comment"> * ClassName: DauApp01</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> 18729 created on date: 2020/12/8 11:55</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@version</span> 1.0</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> JDK 1.8</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DauApp01</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String kafkaBrokers = <span class="string">&quot;hadoop01:9092&quot;</span>;</span><br><span class="line">        String zkBrokers = <span class="string">&quot;hadoop01:2181,hadoop02:2181,hadoop03:2181&quot;</span>;</span><br><span class="line">        String topic = <span class="string">&quot;GMALL_STARTUP_0105&quot;</span>;</span><br><span class="line">        String groupId = <span class="string">&quot;DAU_GROUP&quot;</span>;</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;===============》 flink任务开始  ==============》&quot;</span>);</span><br><span class="line"></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        <span class="comment">//设置kafka连接参数</span></span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, kafkaBrokers);</span><br><span class="line">        properties.setProperty(<span class="string">&quot;zookeeper.connect&quot;</span>, zkBrokers);</span><br><span class="line">        properties.setProperty(<span class="string">&quot;group.id&quot;</span>, groupId);</span><br><span class="line">        <span class="comment">//设置时间类型</span></span><br><span class="line">        env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</span><br><span class="line">        <span class="comment">//设置检查点时间间隔</span></span><br><span class="line">        env.enableCheckpointing(<span class="number">5000</span>);</span><br><span class="line">        <span class="comment">//创建kafak消费者，获取kafak中的数据</span></span><br><span class="line">        FlinkKafkaConsumer010&lt;String&gt; kafkaConsumer010 = <span class="keyword">new</span> FlinkKafkaConsumer010&lt;&gt;(topic, <span class="keyword">new</span> SimpleStringSchema(), properties);</span><br><span class="line">        DataStreamSource&lt;String&gt; kafkaData = env.addSource(kafkaConsumer010);</span><br><span class="line">        DataStream&lt;String&gt; userData = kafkaData.map(<span class="keyword">new</span> MapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> String <span class="title">map</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;接收topic报文:&quot;</span>+s+<span class="string">&quot;&lt;&lt;&lt;&lt;&lt;&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span> s;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        List&lt;HttpHost&gt; httpHosts = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        httpHosts.add(<span class="keyword">new</span> HttpHost(<span class="string">&quot;hadoop01&quot;</span>, <span class="number">9200</span>, <span class="string">&quot;http&quot;</span>));</span><br><span class="line">        ElasticsearchSink.Builder&lt;String&gt; esSinkBuilder = <span class="keyword">new</span> ElasticsearchSink.Builder&lt;&gt;(</span><br><span class="line">                httpHosts,</span><br><span class="line">                <span class="keyword">new</span> ElasticsearchSinkFunction&lt;String&gt;() &#123;</span><br><span class="line">                    <span class="function"><span class="keyword">public</span> IndexRequest <span class="title">createIndexRequest</span><span class="params">(String element)</span> </span>&#123;</span><br><span class="line">                        Map&lt;String, Object&gt; json = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">                        JSONObject jsonObject = JSON.parseObject(element);</span><br><span class="line"></span><br><span class="line">                        Long ts = jsonObject.getLong(<span class="string">&quot;ts&quot;</span>);</span><br><span class="line">                        String format = <span class="keyword">new</span> SimpleDateFormat(<span class="string">&quot;yyyy-MM-dd HH&quot;</span>).format(<span class="keyword">new</span> Date(ts));</span><br><span class="line">                        String[] s = format.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                        jsonObject.put(<span class="string">&quot;dt&quot;</span>,s[<span class="number">0</span>]);</span><br><span class="line">                        jsonObject.put(<span class="string">&quot;hr&quot;</span>,s[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">                        String common = jsonObject.getString(<span class="string">&quot;common&quot;</span>);</span><br><span class="line">                        JSONObject jsonObject1 = JSON.parseObject(common);</span><br><span class="line"></span><br><span class="line">                        json.put(<span class="string">&quot;mid&quot;</span>,jsonObject1.getString(<span class="string">&quot;mid&quot;</span>));</span><br><span class="line">                        json.put(<span class="string">&quot;uid&quot;</span>,jsonObject1.getString(<span class="string">&quot;uid&quot;</span>));</span><br><span class="line">                        json.put(<span class="string">&quot;ar&quot;</span>,jsonObject1.getString(<span class="string">&quot;ar&quot;</span>));</span><br><span class="line">                        json.put(<span class="string">&quot;ch&quot;</span>,jsonObject1.getString(<span class="string">&quot;ch&quot;</span>));</span><br><span class="line">                        json.put(<span class="string">&quot;vc&quot;</span>,jsonObject1.getString(<span class="string">&quot;vc&quot;</span>));</span><br><span class="line">                        json.put(<span class="string">&quot;dt&quot;</span>,jsonObject.getString(<span class="string">&quot;dt&quot;</span>));</span><br><span class="line">                        json.put(<span class="string">&quot;hr&quot;</span>,jsonObject.getString(<span class="string">&quot;hr&quot;</span>));</span><br><span class="line">                        json.put(<span class="string">&quot;mi&quot;</span>,<span class="string">&quot;00&quot;</span>);</span><br><span class="line">                        json.put(<span class="string">&quot;ts&quot;</span>,jsonObject.getLong(<span class="string">&quot;ts&quot;</span>));</span><br><span class="line">                        System.out.println(<span class="string">&quot;data:&quot;</span>+element);</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">return</span> Requests.indexRequest()</span><br><span class="line">                                .index(<span class="string">&quot;gmall_dau_info_&quot;</span> + jsonObject.getString(<span class="string">&quot;dt&quot;</span>))</span><br><span class="line">                                .type(<span class="string">&quot;_doc&quot;</span>)</span><br><span class="line">                                .id(jsonObject1.getString(<span class="string">&quot;mid&quot;</span>))</span><br><span class="line">                                .source(json);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(String element, RuntimeContext ctx, RequestIndexer indexer)</span> </span>&#123;</span><br><span class="line">                        indexer.add(createIndexRequest(element));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        esSinkBuilder.setBulkFlushMaxActions(<span class="number">1</span>);</span><br><span class="line"><span class="comment">//        esSinkBuilder.setRestClientFactory(</span></span><br><span class="line"><span class="comment">//                restClientBuilder -&gt; &#123;</span></span><br><span class="line"><span class="comment">//                    restClientBuilder.setDefaultHeaders()</span></span><br><span class="line"><span class="comment">//                &#125;</span></span><br><span class="line"><span class="comment">//        );</span></span><br><span class="line">        esSinkBuilder.setRestClientFactory(<span class="keyword">new</span> util.RestClientFactoryImpl());</span><br><span class="line">        esSinkBuilder.setFailureHandler(<span class="keyword">new</span> RetryRejectedExecutionFailureHandler());</span><br><span class="line"></span><br><span class="line">        userData.addSink(esSinkBuilder.build());</span><br><span class="line"></span><br><span class="line">        env.execute(<span class="string">&quot;flink-task&quot;</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="测试："><a href="#测试：" class="headerlink" title="测试："></a>测试：</h4><p>将sparkstreaming任务宕机，然后在打开，从redis读取检查点位置继续消费：</p>
<p><img src="/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/redis1.jpg"></p>
<p><img src="/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/redis2.jpg"></p>
<p>将flink任务宕机，然后在打开，能够继续从检查点消费：</p>
<p><img src="/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/%E6%A3%80%E6%9F%A5%E7%82%B9.jpg"></p>
<p>通过对比可以发现，使用flink代码比使用sparkstreaming简洁很多，原因在于flink内部有保存状态的状态后端，同时sparkstreaming基于微批次处理，flink基于流式处理在数据处理速度上页更加流畅。</p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="https://ycfn97.xyz/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/" data-id="ckifxoqx20000swgaek3mgdtm" class="article-share-link" data-share="baidu" data-title="日活需求(kafka精准一次性消费) 分别用sparkstreaming和flink实现">Share</a>
      

  
  <a href="https://ycfn97.xyz/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/#valine_thread" class="article-comment-link">Comments</a>


      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/12/14/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93-dwd%E5%B1%82%E7%BB%B4%E8%A1%A8%E5%85%B3%E8%81%94/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          flink实时数仓-dwd层维表关联
        
      </div>
    </a>
  
  
    <a href="/2020/12/07/flink-yarn%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84-HA-%E5%92%8C-%E6%95%85%E9%9A%9C%E9%87%8D%E5%90%AF/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">flink yarn模式下的 HA 和 故障重启</div>
    </a>
  
</nav>

  
</article>


  <section id="comments">
    <div id="valine_thread">
      <div class="comment"></div>
    </div>
  </section>
</section>
      
      <aside id="sidebar">
  
    
  
    
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">十一月 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">九月 2020</a><span class="archive-list-count">5</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/12/14/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93-dwd%E5%B1%82%E7%BB%B4%E8%A1%A8%E5%85%B3%E8%81%94/">flink实时数仓-dwd层维表关联</a>
          </li>
        
          <li>
            <a href="/2020/12/08/%E6%97%A5%E6%B4%BB%E9%9C%80%E6%B1%82(kafka%E7%B2%BE%E5%87%86%E4%B8%80%E6%AC%A1%E6%80%A7%E6%B6%88%E8%B4%B9)-%E5%88%86%E5%88%AB%E7%94%A8sparkstreaming%E5%92%8Cflink%E5%AE%9E%E7%8E%B0/">日活需求(kafka精准一次性消费) 分别用sparkstreaming和flink实现</a>
          </li>
        
          <li>
            <a href="/2020/12/07/flink-yarn%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84-HA-%E5%92%8C-%E6%95%85%E9%9A%9C%E9%87%8D%E5%90%AF/">flink yarn模式下的 HA 和 故障重启</a>
          </li>
        
          <li>
            <a href="/2020/12/04/clickhouse%E4%BD%9C%E4%B8%BA%E5%AE%9E%E6%97%B6%E5%92%8C%E7%A6%BB%E7%BA%BF%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E4%BB%8Ekafka%E6%B6%88%E8%B4%B9%E6%95%B0%E6%8D%AE/">clickhouse作为实时和离线计算引擎从kafka消费数据</a>
          </li>
        
          <li>
            <a href="/2020/11/15/%E4%B8%80%E6%AC%A1%E6%84%8F%E5%A4%96%E6%96%AD%E7%94%B5%E5%AF%BC%E8%87%B4mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8D%9F%E5%9D%8F%E7%9A%84%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B/">一次意外断电导致mysql数据库损坏的数据恢复过程</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Links</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="https://github.com/ycfn97" target="_blank">github</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 ycfn97  &nbsp WeChat: ycfnsq97<br> 
<!--      Powered by <a href="//hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/xiangming/landscape-plus" target="_blank">Landscape-plus</a>     -->


<br>

    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人</span>



    </div>
  </div>
</footer>

  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
  <!-- totop start -->
<div id="totop">
<a title="totop"><img src="/img/scrollup.png"/></a>
</div>

<!-- totop end -->




<!--载入js，在</body>之前插入即可-->
    <!--Leancloud 操作库:-->
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <!--Valine 的核心代码库-->
    <script src="/js/Valine.min.js"></script>
    <script>
        new Valine({
            av: AV, 
            el: '.comment',
            app_id: 'ybyFTNXr5dkNt6FJvnChNvzH-gzGzoHsz',
            app_key: 'QBdhhOEgw2lDsDrAKD8khsGr',
            placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!',
        });
    </script>




<!-- 百度分享 start -->

<div id="article-share-box" class="article-share-box">
  <div id="bdshare" class="bdsharebuttonbox article-share-links">
    <a class="article-share-weibo" data-cmd="tsina" title="分享到新浪微博"></a>
    <a class="article-share-weixin" data-cmd="weixin" title="分享到微信"></a>
    <a class="article-share-qq" data-cmd="sqq" title="分享到QQ"></a>
    <a class="article-share-renren" data-cmd="renren" title="分享到人人网"></a>
    <a class="article-share-more" data-cmd="more" title="更多"></a>
  </div>
</div>
<script>
  function SetShareData(cmd, config) {
    if (shareDataTitle && shareDataUrl) {
      config.bdText = shareDataTitle;
      config.bdUrl = shareDataUrl;
    }
    return config;
  }
  window._bd_share_config={
    "common":{onBeforeClick: SetShareData},
    "share":{"bdCustomStyle":"/css/bdshare.css"}
  };
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

<!-- 百度分享 end -->

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>





<script src="/js/script.js"></script>




<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https'){
   bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
  bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>






</div>
</body>
</html>
